{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Коллаборативная фильтрация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезная ссылка на рекомендательную систему на Kaggle:\n",
    "\n",
    "https://www.kaggle.com/sjj118/movie-visualization-recommendation-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1       31     2.5\n",
       "1       1     1029     3.0\n",
       "2       1     1061     3.0\n",
       "3       1     1129     2.0\n",
       "4       1     1172     4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:\\\\myIT\\\\myProjects\\\\sberbank\\\\recomendation_system_181120\\\\the_movies_dataset\\\\'\n",
    "\n",
    "ratings = pd.read_csv(path + 'ratings_small.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У тебя появился доступ к идентификатору пользователя (userId), идентификатору фильма (movieId) и к рейтинговой оценке (rating), которую пользователь поставил конкретному фильму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть названия фильмов, которые посмотрел и оценил пользователь, возьмем данные нашего основного файла «movies_metadata_fixed.csv». Загрузи названия кино (title) и объедини два датасета методом **merge** по столбцам **movieId** слева и **id** справа, а затем удали дубликат столбца **id**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Rocky III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jay and Silent Bob Strike Back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Confidentially Yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>My Tutor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating                           title\n",
       "0         1     1371     2.5                       Rocky III\n",
       "182       1     2294     2.0  Jay and Silent Bob Strike Back\n",
       "235       1     2455     2.5            Confidentially Yours\n",
       "47        1     1405     1.0                           Greed\n",
       "140       1     2193     2.0                        My Tutor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузи из movies_metadata_fixed.csv столбцы ['id', 'title']\n",
    "movies = pd.read_csv(path + 'movies_metadata_fixed.csv', usecols=['id', 'title'])\n",
    "\n",
    "#Объедини таблицы при помощи метода merge\n",
    "info = pd.merge(ratings, movies, left_on='movieId', right_on='id').sort_values('userId')\n",
    "#Удали столбец-дубликат\n",
    "info = info.drop('id', axis=1)\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы дальше не путаться в идентификационных номерах, немного изменим их. Фильмов в основном наборе данных по количеству больше, чем в сокращенном файле «ratings_small.csv». Это значит, что в колонке **movieId** будут пропуски в порядке номеров. Например, изначально у нас есть 100 фильмов, но мы случайным образом в датасет отобрали 5 фильмов с идентификаторами: 1, 3, 12, 55, 79. Будет гораздо удобнее, если в объединенном датасете id этих фильмов будут: 1, 2, 3, 4, 5. Поэтому сейчас мы заново присвоим id фильмам в объединенном датасете, чтобы нумерация совпадала с числом фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Rocky III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jay and Silent Bob Strike Back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Confidentially Yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Greed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>My Tutor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating                           title\n",
       "0         1        1     2.5                       Rocky III\n",
       "182       1        2     2.0  Jay and Silent Bob Strike Back\n",
       "235       1        3     2.5            Confidentially Yours\n",
       "47        1        4     1.0                           Greed\n",
       "140       1        5     2.0                        My Tutor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids = info['movieId'].unique()\n",
    "\n",
    "def scale_movie_id(movie_id):\n",
    "    scaled = np.where(movie_ids == movie_id)[0][0] + 1\n",
    "    return scaled\n",
    "\n",
    "info['movieId'] = info['movieId'].apply(scale_movie_id)\n",
    "\n",
    "user_ids = info['userId'].unique()\n",
    "\n",
    "def scale_user_id(user_id):\n",
    "    scaled = np.where(user_ids == user_id)[0][0] + 1\n",
    "    return scaled\n",
    "\n",
    "info['userId'] = info['userId'].apply(scale_user_id)\n",
    "\n",
    "n_movies = len(info['movieId'].unique())\n",
    "n_users = len(info['userId'].unique())\n",
    "\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44994, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ты точно не пропустишь фильм и не запутаешься в идентификаторах при работе с кодом твоей программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание рейтинговых оценок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь тебе нужно разделить получившийся набор данных на две части: обучающую (train) и тестовую (test) выборку. Когда мы делаем предсказание, наша задача — получить честный прогноз. Как мы узнаем, что предсказания оценок близки к действительным оценкам? Мы можем обучить модель на одной части нашего набора данных и проверить на второй, как хорошо модель справляется с угадыванием оценок. Поэтому первую часть выборки ты используешь для обучения, а на второй части измеришь качество предсказанных оценок. \n",
    "\n",
    "Чтобы разделить датасет на две части случайным образом, используй фукцию **train_test_split** из библиотеки **scikit-learn**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (35995, 4)\n",
      "Test shape:  (8999, 4)\n"
     ]
    }
   ],
   "source": [
    "#Загрузи библиотеку scikit-learn и разбей выборку на две: train и test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(info, test_size=0.2)\n",
    "\n",
    "print('Train shape: ', train_data.shape)\n",
    "print('Test shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определять качество предсказанных оценок будем с помощью показателя ошибки модели — RMSE.\n",
    "\n",
    "Давай напишем функцию, чтобы проводить оценку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    # Оставь оценки, предсказанные алгоритмом, только для нужного набора данных\n",
    "    prediction = np.nan_to_num(prediction)[ground_truth.nonzero()].flatten()\n",
    "    # Оставь действительные оценки пользователей только для соотвествующего набора данных\n",
    "    ground_truth = np.nan_to_num(ground_truth)[ground_truth.nonzero()].flatten()\n",
    "    \n",
    "    mse = mean_squared_error(prediction, ground_truth)\n",
    "    return sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь нужно подготовить и сформировать матрицы\n",
    "- для тренировочной выборки с действительными оценками пользователей \n",
    "- для обучающей выборки с предсказанными оценками\n",
    "\n",
    "Обе матрицы должны быть **размера (n_users, n_movies)**, чтобы элемент в ячейке **[i,j]** отражал оценку **i-го** пользователя **j-му** фильму:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38981</th>\n",
       "      <td>624</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Very Annie Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12370</th>\n",
       "      <td>303</td>\n",
       "      <td>90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Fools Rush In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>497</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Once Were Warriors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating               title\n",
       "38981     624     1170     3.0     Very Annie Mary\n",
       "12370     303       90     3.5       Fools Rush In\n",
       "4692      497       44     5.0  Once Were Warriors"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строка датафрейма берется как кортеж, \n",
    "# в ячейку userId-movieId (индексы [line[1] - 1, line[2] - 1]) записываем оценку rating (line[3])\n",
    "train_data_matrix = np.zeros((n_users, n_movies))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n",
    "    \n",
    "test_data_matrix = np.zeros((n_users, n_movies))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1] - 1, line[2] - 1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 2830)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что часть оценок попала в обучающую выборку **train_data_matrix**, а другая часть в тестовую — **test_data_matrix**, чтобы можно было оценить качество предсказаний.\n",
    "\n",
    "Дальше, нужно понять, как именно предсказывать оценки. В системах коллаборативной фильтрации для этого используют два подхода:\n",
    "- user-based или «рекомендации, основанные на пользователях», когда мы ищем похожих пользователей\n",
    "- item-based или «рекомендации, основанные на объектах», когда мы ищем похожие объекты, то есть похожие фильмы в задании\n",
    "\n",
    "Осталось понять, как реализовать поиск похожих пользователей и фильмов, как мы это будем определять? Есть разные подходы, один из них — использовать **косинусное расстояние** между векторами, в которых хранится описание пользователей и фильмов. Косинусное растояние считается по формуле: \n",
    "\n",
    "$$similarity = cos(\\theta) = \\dfrac{A \\cdot B}{||A|| \\cdot ||B||} = \\dfrac{\\sum (A_i \\cdot B_i)}{\\sqrt{\\sum (A_i)^2} \\cdot \\sqrt{\\sum (B_i)^2}} $$\n",
    "\n",
    "\n",
    "- $A$ - первый вектор с оценками зрителя № 1 за все фильмы\n",
    "- $B$ - второй вектор с оценками зрителя № 2 за все фильмы\n",
    "- $||A||$ - длина вектора A, это сумма квадратов элементов под корнем.\n",
    "- $||B||$ - длина вектора B, это сумма квадратов элементов под корнем.\n",
    "- $A \\cdot B$ - сумма поэлементного произведения векторов (скалярное произведение векторов).\n",
    "Например, вектор оценок A = {1, 2, 5}, вектор оценок B = {3, 4, 2}\n",
    "Тогда скалярное произведение мы вычисляем так: $A \\cdot B = 1 \\cdot 3 + 2 \\cdot 4 + 5 \\cdot 2 = 21$\n",
    "\n",
    "Хорошие новости — в библиотеке **Scikit-learn** уже есть готовая функция **pairwise_distances**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# считаем косинусное расстояние для пользователей и фильмов \n",
    "# (по строкам и по колонкам соотвественно).\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде:\n",
    "- user_similarity[i][j] — косинусное расстояние между i-ой строкой и j-ой строкой;\n",
    "- item_similarity[i][j] — косинусное расстояние между i-ой и j-ой колонками.\n",
    "\n",
    "Будем считать, что косинусное расстояние обозначает степень похожести: **чем пользователи или фильмы более похожи друг на друга — тем меньше будет косинусное расстояние**. Посмотри, как это работает на небольшом примере. Представим, у нас есть оценки твоих знакомых для нескольких фильмов, соберем их в один датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Хоббит</th>\n",
       "      <th>Мстители</th>\n",
       "      <th>Человек-паук</th>\n",
       "      <th>Матрица</th>\n",
       "      <th>Звездные войны</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Маша</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Миша</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ваня</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Настя</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Хоббит  Мстители  Человек-паук  Матрица  Звездные войны\n",
       "Маша        0         5             1        5               0\n",
       "Миша        4         5             0        4               3\n",
       "Ваня        0         0             1        2               1\n",
       "Настя       4         5             2        3               4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#создаем датафрейм со случайными оценками\n",
    "d = {\"Хоббит\":         pd.Series([0, 4, 0, 4], index=['Маша', 'Миша', 'Ваня', 'Настя']), \n",
    "     \"Мстители\":       pd.Series([5, 5, 0, 5], index=['Маша', 'Миша', 'Ваня', 'Настя']), \n",
    "     \"Человек-паук\":   pd.Series([1, 0, 1, 2], index=['Маша', 'Миша', 'Ваня', 'Настя']), \n",
    "     \"Матрица\":        pd.Series([5, 4, 2, 3], index=['Маша', 'Миша', 'Ваня', 'Настя']),\n",
    "     \"Звездные войны\": pd.Series([0, 3, 1, 4], index=['Маша', 'Миша', 'Ваня', 'Настя'])}\n",
    "df1 = pd.DataFrame(d)\n",
    "\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы становится ясно, что Маша ещё не смотрела \"Хоббита\" и \"Звездные войны\". Теперь создаем датафрейм, где сохраним косинусное расстояние между ребятами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Маша</th>\n",
       "      <th>Миша</th>\n",
       "      <th>Ваня</th>\n",
       "      <th>Настя</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Маша</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Миша</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ваня</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Настя</th>\n",
       "      <td>0.297</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Маша   Миша   Ваня  Настя\n",
       "Маша   0.000  0.224  0.371  0.297\n",
       "Миша   0.224  0.000  0.447  0.044\n",
       "Ваня   0.371  0.447  0.000  0.414\n",
       "Настя  0.297  0.044  0.414  0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = pairwise_distances(df1, metric='cosine')\n",
    "dist = np.round(dist, 3)\n",
    "dist_df = pd.DataFrame(data=dist, index = ['Маша', 'Миша', 'Ваня', 'Настя'], columns=['Маша', 'Миша', 'Ваня', 'Настя'])\n",
    "display(dist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат смотрим по строке и узнаем, что два самых похожих на Машу пользователя (по косиносному расстоянию) — это Миша (0.224) и Настя (0.297). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше ты попробуешь использовать оба подхода для написания программы:\n",
    "- User-based коллаборативная фильтрация (предскажем оценки фильмам на основе \"похожести\" пользователей)\n",
    "- Item-Based коллаборативная фильтрация (предскажем оценки фильмам на основе \"похожести\" фильмов). \n",
    "\n",
    "Подходы отличаются только матрицами оценок, алгоритм остается одинаковым. Если в User-based подходе фильмы располагаются по столбцам, а пользователи по строкам, то в Item-Based подходе фильмы располагаются в строках, а пользователи — в колонках. Мы с тобой реализуем три варианта систем коллаборативной фильтрации и в каждой попробуем использовать оба подхода, но в разных форматах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый вариант модели\n",
    "\n",
    "Начнём с самого простого алгоритма коллаборативной фильтрации. Оценка, которую мы хотим предсказать — это среднее арифмитическое оценок этого фильма от зрителей, похожих на нашего пользователя.\n",
    "\n",
    "Предсказанная оценка(**u**) определяется так:  оценка **u** по фильму **i** равна средней оценке фильма **i** от **N** пользователей, которые больше всего похожи на пользователя **u**. А похожих пользователей мы отобрали выше, вычислив косинусное расстояние между ними.\n",
    "\n",
    "Для вычисления оценки мы используем следующую формулу:\n",
    "\n",
    "$$  R = \\cfrac{\\sum r_k}{N} $$\n",
    "\n",
    "- $U$ - пользователь, для которого предсказыааем оценку\n",
    "- $i$ - фильм, для которого предсказываем оценку пользователя U\n",
    "- $R$ - предсказанная оценка пользователя U за фильм i \n",
    "- $r_k$ - оценка пользователя k, который похож на пользователя U, за фильм i\n",
    "- $\\sum r_k $ - сумма оценок всех похожих на пользователя U зрителей за фильм i\n",
    "- $N$ - количество зрителей, похожих на пользователя U\n",
    "\n",
    "\n",
    "Помнишь пример выше, где мы рассчитали косинусное расстояние между зрителями? Маша не смотрела \"Хоббита\" и \"Звездные войны\", вот как бы мы предсказали её оценки вручную. Напомним, самые похожие зрители с Машей это Миша и Настя, поэтому мы берем их оценки для расчёта:\n",
    "\n",
    "**Предсказанная оценка Маши для фильма \"Хоббит\"**\n",
    "\n",
    "- оценка Мишы за фильм \"Хоббит\" = 4\n",
    "- оценка Насти за фильм \"Хоббит\" = 4\n",
    "\n",
    "$  R_{Маша, Хоббит} = \\cfrac{4 + 4}{2} = 4$\n",
    "\n",
    "**Предсказанная оценка Маши для фильма \"Звездные войны\"**\n",
    "\n",
    "- оценка Мишы за фильм \"Звездные войны\" = 3\n",
    "- оценка Насти за фильм \"Звездные войны\" = 4\n",
    "\n",
    "$  R_{Маша, ЗВ} = \\cfrac{3 + 4}{2} = 3.5$\n",
    "\n",
    "Теперь проделаем такой же расчёт для твоего основного датасета в задании: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34, 324, 633, 476,  40, 345,   6], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity[0].argsort()[1:7 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE:  2.7986936341957986\n",
      "Item-based CF RMSE:  2.911539468595995\n"
     ]
    }
   ],
   "source": [
    "# User-based коллаборативная фильтрация\n",
    "def naive_predict(top):\n",
    "    # Структура хранения оценки фильмов от самых похожих пользователей для каждого зрителя\n",
    "    # (количество похожих пользователей хранится в переменной top):\n",
    "    # top_similar_ratings[0][1] - оценки всех фильмов одного из самых похожих пользователей на зрителя с id 0.\n",
    "    # Здесь 1 - это не id пользователя, а просто порядковый номер.\n",
    "    top_similar_ratings = np.zeros((n_users, top, n_movies))\n",
    "\n",
    "    for i in range(n_users):\n",
    "        # Для каждого зрителя необходимо найти наиболее похожих пользователей:\n",
    "        # нулевой элемент не учитываем, так как на этом месте хранится похожесть пользователя самого на себя\n",
    "        top_sim_users = user_similarity[i].argsort()[1:top + 1] #здесь в top_sim_users мы записываем id пользователей, у которых косинусные расстояния самые маленькие до текущего пользователя i\n",
    "        \n",
    "        # берём только оценки из \"обучающей\" выборки \n",
    "        top_similar_ratings[i] = train_data_matrix[top_sim_users] #создаём таблицу для каждого пользователя, в которой хранятся оценки за все фильмы от похожих пользователей\n",
    "\n",
    "    pred = np.zeros((n_users, n_movies))\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        pred[i] = top_similar_ratings[i].sum(axis=0) / top #применяем формулу, описанную выше. \n",
    "        #top_similar_ratings[i].sum(axis=0) - это сумма оценок \"похожих\" пользователей, top - количество \"похожих\" пользователей\n",
    "     \n",
    "    return pred\n",
    "\n",
    "\n",
    "def naive_predict_item(top):\n",
    "    top_similar_ratings = np.zeros((n_movies, top, n_users))\n",
    "\n",
    "    for i in range(n_movies):\n",
    "        top_sim_movies = item_similarity[i].argsort()[1:top + 1] #находим наиболее близкие фильмы по оценкам\n",
    "\n",
    "        top_similar_ratings[i] = train_data_matrix.T[top_sim_movies] #создаём таблицу для каждого фильма, в которой хранятся оценки всех пользователей за похожие фильмы \n",
    "        \n",
    "    pred = np.zeros((n_movies, n_users))\n",
    "    for i in range(n_movies):\n",
    "        pred[i] = top_similar_ratings[i].sum(axis=0) / top #применяем формулу, описанную выше, только для фильмов, а не пользователей \n",
    "    \n",
    "    return pred.T\n",
    "\n",
    "naive_pred = naive_predict(7) #вызываем первую функцию, user-based, количество \"похожих\" пользователей - 7, передаём как аргумент\n",
    "print('User-based CF RMSE: ', rmse(naive_pred, test_data_matrix))\n",
    "\n",
    "naive_pred_item = naive_predict_item(7) #вызываем вторую функцию, item-based, количество \"похожих\" фильмов - 7, передаём как аргумент\n",
    "print('Item-based CF RMSE: ', rmse(naive_pred_item, test_data_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй вариант модели\n",
    "\n",
    "Попробуем посторить другой вариант алгоритма, он будет опираться на две матрицы: \"похожести пользователей\" и оценок \"похожих\" пользователей. В этом варианте мы ожидаем, что похожие зрители будут ставить примерно похожие оценки фильмам, и так алгоритм сможет предсказать оценки. Для этого мы используем следующую формулу:\n",
    "\n",
    "$$R = \\cfrac{\\sum (Sim_k \\cdot r_k)}{\\sum Sim}$$\n",
    "\n",
    "- $R$ - предсказанная оценка пользователя U за фильм i \n",
    "- $Sim_k$ - \"похожесть\" пользователя k на пользователя U, в нашем случае, это косинусное расстояние\n",
    "- $r_k$ - оценка пользователя k за фильм i\n",
    "- $\\sum Sim $ - сумма косинусных расстояний всех похожих пользователей\n",
    "\n",
    "Помнишь из примера выше, что Маша ещё не смотрела фильм \"Хоббит\" и \"Звездные войны\"? Стоит ли посоветовать ей это кино? Мы должны предсказать её оценку, чтобы дать удачную рекомендацию. Из нашей матрицы \"похожести пользователей\" мы вновь берем зрителей - Мишу и Настю, они похожи на Машу больше других по косинусному расстоянию. В этой модели, чем больше похожи пользователи, тем сильнее оценка такого зрителя влияет на предсказанную оценку.\n",
    "\n",
    "\n",
    "**Для фильма \"Хоббит\"**\n",
    "\n",
    "- оценка Мишы за фильм = 4\n",
    "- расстояние до Миши = 0.224\n",
    "\n",
    "\n",
    "- оценка Насти за фильм  = 4\n",
    "- расстояние до Насти = 0.297\n",
    "\n",
    "**Предсказание оценки Маши для фильма \"Хоббит\"**\n",
    "\n",
    "$  R_{Маша, Хоббит} = \\cfrac{0.224 \\cdot 4 + 0.297 \\cdot 4}{0.224 + 0.297} = \\cfrac{2.084}{0.521} = 4$\n",
    "\n",
    "\n",
    "**Для фильма \"Звездные войны\"**\n",
    "\n",
    "- оценка Мишы за фильм = 3\n",
    "- расстояние до Миши = 0.224\n",
    "\n",
    "\n",
    "- оценка Насти за фильм  = 4\n",
    "- расстояние до Насти = 0.297\n",
    "\n",
    "**Предсказание оценки Маши для фильма \"Звездные войны\"**\n",
    "\n",
    "$  R_{Маша, ЗВ} = \\cfrac{0.224 \\cdot 3 + 0.297 \\cdot 4}{0.224 + 0.297} = \\cfrac{1.86}{0.521} = 3.57$\n",
    "\n",
    " Посмотрим, как реализовать вторую модель для твоего основного набора данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE:  2.799920346052418\n",
      "Item-based CF RMSE:  3.0025760769134684\n"
     ]
    }
   ],
   "source": [
    "def k_fract_predict(top):\n",
    "    top_similar = np.zeros((n_users, top))\n",
    "    \n",
    "    for i in range(n_users): #создаём массив, в котором будем хранить для каждого пользователя id \"похожих\" на него пользователей\n",
    "        user_sim = user_similarity[i]\n",
    "        top_sim_users = user_sim.argsort()[1:top + 1]#[-top:]\n",
    "\n",
    "        top_similar[i] = top_sim_users\n",
    "            \n",
    "    pred = np.zeros((n_users, n_movies))\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        indexes = top_similar[i].astype(np.int) #записываем id людей, \"похожих\" на пользователя i в отдельную переменную\n",
    "        numerator = user_similarity[i][indexes] #записываем в отдельную переменную вектор с косинусными расстояниями до ближайших \"похожих\" людей для пользователя i\n",
    "        \n",
    "        product = np.dot(numerator, train_data_matrix[indexes]) #Здесь мы реализуем вычисления для числителя в нашей формуле, но сразу для всех, перемножая между собой матрицы\n",
    "        #первая матрица содержит в себе косинусное расстояние до ближайших \"похожих\" пользователей\n",
    "        #вторая матрица содержит оценки этих пользователей за все фильмы\n",
    "        \n",
    "        denominator = numerator.sum() #сумма расстояний до \"похожих\" пользователей, наш знаменатель\n",
    "        \n",
    "        pred[i] = product / denominator #вычисляем значения для нашего вектора с предсказанными оценками пользователя i для всех фильмов\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def k_fract_predict_item(top):\n",
    "    top_similar = np.zeros((n_movies, top))\n",
    "    \n",
    "    for i in range(n_movies): #создаём массив, в котором будем хранить для каждого фильма id \"похожих\" на него фильмов\n",
    "        movies_sim = item_similarity[i]\n",
    "        top_sim_movies = movies_sim.argsort()[1:top + 1]\n",
    "\n",
    "        top_similar[i] = top_sim_movies.T\n",
    "            \n",
    "    pred = np.zeros((n_movies, n_users))\n",
    "    \n",
    "    \n",
    "    for i in range(n_users):\n",
    "        indexes = top_similar[i].astype(np.int) #записываем id фильмов, \"похожих\" на фильм i в отдельную переменную\n",
    "        numerator = item_similarity[i][indexes] #записываем в отдельную переменную вектор с косинусными расстояниями до ближайших \"похожих\" фильмов для фильма i \n",
    "        \n",
    "        product = np.dot(numerator, train_data_matrix.T[indexes])#Здесь мы реализуем вычисления для числителя в нашей формуле, но сразу для всех, перемножая между собой матрицы\n",
    "        #первая матрица содержит в себе косинусное расстояние до ближайших \"похожих\" фильмов\n",
    "        #вторая матрица содержит оценки всех пользователей за \"похожие\" фильмы\n",
    "        \n",
    "        denominator = numerator.sum() #сумма расстояний до \"похожих\" фильмов, наш знаменатель\n",
    "        \n",
    "        pred[i] = product / denominator #вычисляем значения для нашего вектора с предсказанными оценками за фильм i для всех пользователей\n",
    "        \n",
    "    return pred.T\n",
    "\n",
    "\n",
    "k_predict = k_fract_predict(7) #вызываем первую функцию, user-based, количество \"похожих\" пользователей - 7, передаём как аргумент\n",
    "print('User-based CF RMSE: ', rmse(k_predict, test_data_matrix))\n",
    "\n",
    "k_predict_item = k_fract_predict_item(7) #вызываем вторую функцию, item-based, количество \"похожих\" фильмов - 7, передаём как аргумент\n",
    "print('Item-based CF RMSE: ', rmse(k_predict_item, test_data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.13938332, 0.        , 0.15415952, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.43689037, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Третий вариант модели\n",
    "\n",
    "Третий вариант, который ты дальше попробуешь запрограммировать, зависит от 1) среднего значения всех оценок, которые зритель до этого оставил фильмам, 2) от средних оценок \"похожих\" пользователей\" и 3) от коэффициентов “похожести” зрителей. \n",
    "\n",
    "Для этого мы используем следующую формулу:\n",
    "\n",
    "$$  R = \\overline{R} + \\cfrac{\\sum \\left(Sim_k \\cdot (r_k - \\overline{r_k})\\right)}{\\sum Sim} $$\n",
    "\n",
    "- $R$ - предсказанная оценка пользователя U за фильм i \n",
    "- $\\overline{R}$ - средняя оценка пользователя U по всем фильмам, которые он смотрел\n",
    "- $Sim_k$ - \"похожесть\" пользователя k на пользователя U, в нашем случае, это косинусное расстояние\n",
    "- $r_k$ - оценка пользователя k за фильм i\n",
    "- $\\overline{r_k}$ - средняя оценка пользователя k по всем фильмам, которые он смотрел\n",
    "- $\\sum Sim $ - сумма косинусных расстояний всех похожих пользователей\n",
    "\n",
    "Давай вернемся к примеру. Мы все ещё хотим узнать, как бы Маша оценила фильмы \"Хоббит\" и \"Звездные войны\". Из истории просмотров мы знаем, что Миша и Настя самые похожие на Машу зрители.\n",
    "\n",
    "Предскажем оценку Маши для двух фильмов:\n",
    "\n",
    "**Для начала посчитаем средние оценки по всем фильмам для каждого пользователя**\n",
    "\n",
    "- средняя оценка Маши за все фильмы = $\\cfrac{5 + 1 + 5}{3} = 3.67$\n",
    "- средняя оценка Миши за все фильмы = $\\cfrac{4 + 5 + 4 + 3}{4} = 4$\n",
    "- средняя оценка Насти за все фильмы = $\\cfrac{4 + 5 + 2 + 3 + 4}{5} = 3.6$\n",
    "\n",
    "**Для фильма \"Хоббит\"**\n",
    "\n",
    "- оценка Мишы за фильм = 4\n",
    "- расстояние до Миши = 0.224\n",
    "\n",
    "- оценка Насти за фильм  = 4 \n",
    "- расстояние до Насти = 0.297\n",
    "\n",
    "**Предсказание оценки Маши для фильма \"Хоббит\"**\n",
    "\n",
    "$  R_{Маша, Хоббит} = 3.67 + \\cfrac{0.224 \\cdot (4-4) + 0.297 \\cdot (4-3.6)}{0.224 + 0.297} = 3.67 + \\cfrac{0.1188}{0.521} = 3.898$\n",
    "\n",
    "**Для фильма \"Звездные войны\"**\n",
    "\n",
    "- оценка Мишы за фильм = 3\n",
    "- расстояние до Миши = 0.224\n",
    "\n",
    "- оценка Насти за фильм  = 4\n",
    "- расстояние до Насти = 0.297\n",
    "\n",
    "**Предсказание оценки Маши для фильма \"Звездные войны\"**\n",
    "\n",
    "$  R_{Маша, ЗВ} = 3.67 + \\cfrac{0.224 \\cdot (3-4) + 0.297 \\cdot (4-3.6)}{0.224 + 0.297} = 3.67 + \\cfrac{-0.1052}{0.521} = 3.47$\n",
    "\n",
    "Мы получили предполагаемые оценки Маши за два фильма. Вернись к заданию и попробуй использовать идею расчётов для третьей модели на основном наборе данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE:  1.3970299115503924\n",
      "Item-based CF RMSE:  1.3545026504487854\n"
     ]
    }
   ],
   "source": [
    "def k_fract_mean_predict(top):\n",
    "    top_similar = np.zeros((n_users, top))\n",
    "    \n",
    "    for i in range(n_users): #создаём массив, в котором будем хранить для каждого пользователя id \"похожих\" на него пользователей\n",
    "        user_sim = user_similarity[i]\n",
    "        top_sim_users = user_sim.argsort()[1:top + 1]\n",
    "\n",
    "        top_similar[i] = top_sim_users\n",
    "\n",
    "    pred = np.zeros((n_users, n_movies))\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        indexes = top_similar[i].astype(np.int) #записываем id людей, \"похожих\" на пользователя i в отдельную переменную\n",
    "        numerator = user_similarity[i][indexes] #записываем в отдельную переменную вектор с косинусными расстояниями до ближайших \"похожих\" людей для пользователя i\n",
    "        \n",
    "        mean_rating = np.array([x for x in train_data_matrix[i] if x > 0]).mean() #вычисляем средний рейтинг пользователя i по всем фильмам, которые он посмотрел, если рейтинг равен 0, то не учитываем его\n",
    "        \n",
    "        diff_ratings = train_data_matrix[indexes] - train_data_matrix[indexes].mean() #находим разность между оценкой за конкретный фильм и средней оценкой по всем фильмам для всех \"похожих\" пользователей\n",
    "        \n",
    "        product = np.dot(numerator, diff_ratings) #Здесь мы реализуем вычисления для числителя в нашей формуле, но сразу для всех пользователей, перемножая между собой матрицы\n",
    "        #первая матрица содержит в себе косинусное расстояние до ближайших \"похожих\" пользователей\n",
    "        #вторая матрица содержит результаты вычитания средней оценки из реальной оценки этих пользователей за все фильмы\n",
    "        \n",
    "        denominator = numerator.sum() #сумма расстояний до \"похожих\" пользователей, наш знаменатель\n",
    "      \n",
    "        pred[i] =  mean_rating + product / denominator #вычисляем значения для нашего вектора с предсказанными оценками пользователя i для всех фильмов\n",
    "        \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def k_fract_mean_predict_item(top):\n",
    "    top_similar = np.zeros((n_movies, top))\n",
    "    \n",
    "    for i in range(n_movies): #создаём массив, в котором будем хранить для каждого фильма id \"похожих\" на него фильмов\n",
    "        movie_sim = item_similarity[i]\n",
    "       \n",
    "        top_sim_movies = movie_sim.argsort()[1:top + 1]\n",
    "        \n",
    "        top_similar[i] = top_sim_movies\n",
    "           \n",
    "    pred = np.zeros((n_movies, n_users))\n",
    "    \n",
    "    for i in range(n_movies):\n",
    "        indexes = top_similar[i].astype(np.int) #записываем id фильмов, \"похожих\" на фильм i в отдельную переменную\n",
    "        numerator = item_similarity[i][indexes] #записываем в отдельную переменную вектор с косинусными расстояниями до ближайших \"похожих\" фильмов для фильма i \n",
    "\n",
    "        mean_rating = np.array([x for x in train_data_matrix.T[i] if x > 0]).mean() #вычисляем средний рейтинг фильма i по всем пользователям, которые его посмотрели\n",
    "        \n",
    "        diff_ratings = train_data_matrix.T[indexes] - train_data_matrix.T[indexes].mean() #находим разность между оценкой конкретного пользователя и средней оценкой по всем пользователям для всех \"похожих\" фильмов\n",
    "        \n",
    "        product = np.dot(numerator, diff_ratings) #Здесь мы реализуем вычисления для числителя в нашей формуле, но сразу для всех фильмов, перемножая между собой матрицы\n",
    "        #первая матрица содержит в себе косинусное расстояние до ближайших \"похожих\" фильмов\n",
    "        #вторая матрица содержит результаты вычитания средней оценки из реальной оценки для этих фильмов от всех пользователей\n",
    "        \n",
    "        denominator = numerator.sum() #сумма расстояний до \"похожих\" фильмов, наш знаменатель\n",
    "        \n",
    "        pred[i] = mean_rating + product / denominator #вычисляем значения для нашего вектора с предсказанными оценками для фильма i по всем пользователям\n",
    "        \n",
    "    return pred.T\n",
    "\n",
    "k_predict = k_fract_mean_predict(25) #вызываем первую функцию, user-based, количество \"похожих\" пользователей - 7, передаём как аргумент\n",
    "print('User-based CF RMSE: ', rmse(k_predict, test_data_matrix))\n",
    "\n",
    "k_predict_item = k_fract_mean_predict_item(25) #вызываем вторую функцию, item-based, количество \"похожих\" фильмов - 7, передаём как аргумент\n",
    "print('Item-based CF RMSE: ', rmse(k_predict_item, test_data_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если захочется выгрузить с переименованием строк-столбцов как в kaggle соревновании, то делаем вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution = pd.DataFrame(k_predict)\n",
    "# # 671 пользовательских оценок (строки) по 2830 фильмам (столбцы)\n",
    "# solution.head()\n",
    "\n",
    "# # переименовываем столбцы и строки как требуется в форме для каггла\n",
    "# col = []\n",
    "# for  i in range(n_movies):\n",
    "#     col.append('movie '+str(i))\n",
    "\n",
    "# solution.index.names = ['id'] \n",
    "# solution.columns = col\n",
    "\n",
    "# # выгружаем в csv файл\n",
    "# solution.to_csv('collaboration_rec_system_191120_solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вместо заключения\n",
    "\n",
    "\n",
    "Ты дошёл до конца финального проекта по созданию рекомендательных систем. Поздравляем! Гордимся тобой, ведь у тебя получилось решишь реальную практическую задачу data science профессионала: ты разработал целых три типа систем рекомендаций. Простую неперсональную систему, контентную и систему коллаборативной фильтрации. Какую из них использовать? Это вопрос, на который правильный ответ знаешь только ты. Решение зависит от конкретных условий, ведь всё, что мы запрограммировали, точно используется сегодня в сфрере аналитики данных. \n",
    "\n",
    "**Теперь ты можешь доработать последнюю модель и посоревноваться с другими участниками в лучшем решении в конкурсе на Kaggle**:\n",
    "***www.kaggle.com/c/ai-academy-movie-rating-competition***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
